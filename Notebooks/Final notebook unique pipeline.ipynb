{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "542f2071",
   "metadata": {},
   "source": [
    "<span style='color:darkcyan'><font size=\"3\">__Juan Sebastian Deslarzes__</font></span><br>\n",
    "<span style='color:darkcyan'><font size=\"3\">__Chloé De Ancos__</font></span><br>\n",
    "<span style='color:darkcyan'><font size=\"3\">__Anaïs Burrus__</font></span><br>\n",
    "<span style='color:darkcyan'><font size=\"3\">__Margot Chapot__</font></span><br>\n",
    "<span style='color:darkcyan'><font size=\"3\">__Eva Sarlin__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b8d5e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "  \n",
       "\n",
       "  const inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from IPython import display\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "output_notebook()\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea02d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/evasarlin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from collections import Counter \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd8e154",
   "metadata": {},
   "source": [
    "<span style='color:mediumpurple'><font size=\"6\">__Data Loading__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34777443",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_url = 'https://raw.githubusercontent.com/esarlin/Challenge-2-CDAW/main/sitc-challenge2-2022/sample_submission.csv'\n",
    "test_nolabel_url= 'https://raw.githubusercontent.com/esarlin/Challenge-2-CDAW/main/sitc-challenge2-2022/test_nolabel.csv'\n",
    "train_url = 'https://raw.githubusercontent.com/esarlin/Challenge-2-CDAW/main/sitc-challenge2-2022/train.csv'\n",
    "\n",
    "sample_submission = pd.read_csv(sample_submission_url)\n",
    "test_nolabel = pd.read_csv(test_nolabel_url)\n",
    "df = pd.read_csv(train_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb454c33",
   "metadata": {},
   "source": [
    "<span style='color:mediumpurple'><font size=\"6\">__Feature Selection and Cleaning__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91ba2430",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = df.copy()[[\"statement\", \"subject\", \"speaker\",\"speaker_job\",\"state_info\", \"party_affiliation\"]]\n",
    "test_features = test_nolabel.copy()[[\"statement\", \"subject\", \"speaker\",\"speaker_job\",\"state_info\",\"party_affiliation\"]]\n",
    "target = df.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303f901e",
   "metadata": {},
   "source": [
    "<span style='color:steelblue'><font size=\"4\">__Removing Nan values in Speaker job and state features :__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0001075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features['speaker_job']= data_features['speaker_job'].fillna('u.s. senator')\n",
    "test_features['speaker_job']= test_features['speaker_job'].fillna('u.s. senator')\n",
    "data_features['state_info']= data_features['state_info'].fillna('unknown')\n",
    "test_features['state_info']= test_features['state_info'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879a8b0c",
   "metadata": {},
   "source": [
    "<span style='color:mediumpurple'><font size=\"6\">__NLP__</font></span><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44615301",
   "metadata": {},
   "source": [
    "<span style='color:steelblue'><font size=\"4\">__Defining functions for string processing__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd287f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Transformer \n",
    "class GenericTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return do_something_to(X, self.vars)  # where the actual feature extraction happens\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # used if the feature requires training, for example, clustering\n",
    "    \n",
    "    \n",
    "    \n",
    "class LexicalStats (BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract lexical features from each document\"\"\"\n",
    "    \n",
    "    def number_sentences(self, doc):\n",
    "        sentences = sent_tokenize(doc, language='english')\n",
    "        return len(sentences)\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, docs):\n",
    "        return [{'length': len(doc),\n",
    "                 'num_sentences': self.number_sentences(doc)}\n",
    "                for doc in docs]\n",
    "    \n",
    "def custom_tokenizer(words):\n",
    "    \"\"\"Preprocessing tokens as seen in the lexical notebook\"\"\"\n",
    "    tokens = word_tokenize(words.lower())\n",
    "    porter = PorterStemmer()\n",
    "    lemmas = [porter.stem(t) for t in tokens]\n",
    "    stoplist = stopwords.words('english')\n",
    "    lemmas_clean = [w for w in lemmas if w not in stoplist]\n",
    "    punctuation = set(string.punctuation)\n",
    "    lemmas_punct = [w for w in lemmas_clean if  w not in punctuation]\n",
    "    return lemmas_punct\n",
    "\n",
    "class PosStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Obtain number of tokens with POS categories\"\"\"\n",
    "\n",
    "    def stats(self, doc):\n",
    "        tokens = custom_tokenizer(doc)\n",
    "        tagged = pos_tag(tokens, tagset='universal')\n",
    "        counts = Counter(tag for word,tag in tagged)\n",
    "        total = sum(counts.values())\n",
    "        #copy tags so that we return always the same number of features\n",
    "        pos_features = {'NOUN': 0, 'ADJ': 0, 'VERB': 0, 'ADV': 0, 'CONJ': 0, \n",
    "                        'ADP': 0, 'PRON':0, 'NUM': 0}\n",
    "        \n",
    "        pos_dic = dict((tag, float(count)/total) for tag,count in counts.items())\n",
    "        for k in pos_dic:\n",
    "            if k in pos_features:\n",
    "                pos_features[k] = pos_dic[k]\n",
    "        return pos_features\n",
    "    \n",
    "    def transform(self, docs, y=None):\n",
    "        return [self.stats(doc) for doc in docs]\n",
    "    \n",
    "    def fit(self, docs, y=None):\n",
    "        \"\"\"Returns `self` unless something different happens in train and test\"\"\"\n",
    "        return self\n",
    "    \n",
    "ngrams_featurizer = Pipeline([\n",
    "  ('count_vectorizer',  CountVectorizer(ngram_range = (1, 3), encoding = 'ISO-8859-1', \n",
    "                                        tokenizer=custom_tokenizer)),\n",
    "  ('tfidf_transformer', TfidfTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2de476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer= FeatureUnion([\n",
    "                    ('lexical_stats', Pipeline([\n",
    "                                ('stats', LexicalStats()),\n",
    "                                ('vectors', DictVectorizer())\n",
    "                            ])),\n",
    "                    ('words', TfidfVectorizer(tokenizer=custom_tokenizer)),\n",
    "                    ('ngrams', ngrams_featurizer),\n",
    "                    ('pos_stats', Pipeline([\n",
    "                                ('pos_stats', PosStats()),\n",
    "                                ('vectors', DictVectorizer())\n",
    "                            ])),\n",
    "                    ('lda', Pipeline([ \n",
    "                                ('count', CountVectorizer(tokenizer=custom_tokenizer)),\n",
    "                                ('lda',  LatentDirichletAllocation(n_components=4, max_iter=5,\n",
    "                                                       learning_method='online', \n",
    "                                                       learning_offset=50.,\n",
    "                                                       random_state=0))\n",
    "                            ])),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f66c558",
   "metadata": {},
   "source": [
    "<span style='color:steelblue'><font size=\"4\">__Applying the processing techniques on all the features using ColumnTransformer :__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caa9e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_preprocessor = ColumnTransformer(\n",
    "        [\n",
    "            ('title_glove', transformer, 'statement'),\n",
    "            ('description_glove', transformer, 'subject'),\n",
    "            ('speaker_glove', transformer, 'speaker'),\n",
    "            ('speakerjob_glove', transformer, 'speaker_job'),\n",
    "            ('stateinfo_glove', transformer, 'state_info'),\n",
    "            ('party_glove', transformer, 'party_affiliation'),\n",
    "],\n",
    "        remainder='drop',\n",
    "        n_jobs=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b4d36a",
   "metadata": {},
   "source": [
    "<span style='color:mediumpurple'><font size=\"6\">__Machine Learning algorithm__</font></span><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6e3a5c",
   "metadata": {},
   "source": [
    "<span style='color:steelblue'><font size=\"4\">__Classifier insertion into the pipeline:__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9a62fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_glove = Pipeline([\n",
    "    ('col_preprocessor', col_preprocessor), \n",
    "    ('classifier', MultinomialNB(alpha=.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4ef6d3",
   "metadata": {},
   "source": [
    "<span style='color:steelblue'><font size=\"4\">__Training :__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc0825f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('col_preprocessor',\n",
       "                 ColumnTransformer(n_jobs=1,\n",
       "                                   transformers=[('title_glove',\n",
       "                                                  FeatureUnion(transformer_list=[('lexical_stats',\n",
       "                                                                                  Pipeline(steps=[('stats',\n",
       "                                                                                                   LexicalStats()),\n",
       "                                                                                                  ('vectors',\n",
       "                                                                                                   DictVectorizer())])),\n",
       "                                                                                 ('words',\n",
       "                                                                                  TfidfVectorizer(tokenizer=<function custom_tokenizer at 0x7fe8758713a0>)),\n",
       "                                                                                 ('ngrams',\n",
       "                                                                                  Pipeline(steps=[('count_vectorizer',\n",
       "                                                                                                   CountVector...\n",
       "                                                                                  Pipeline(steps=[('pos_stats',\n",
       "                                                                                                   PosStats()),\n",
       "                                                                                                  ('vectors',\n",
       "                                                                                                   DictVectorizer())])),\n",
       "                                                                                 ('lda',\n",
       "                                                                                  Pipeline(steps=[('count',\n",
       "                                                                                                   CountVectorizer(tokenizer=<function custom_tokenizer at 0x7fe8758713a0>)),\n",
       "                                                                                                  ('lda',\n",
       "                                                                                                   LatentDirichletAllocation(learning_method='online',\n",
       "                                                                                                                             learning_offset=50.0,\n",
       "                                                                                                                             max_iter=5,\n",
       "                                                                                                                             n_components=4,\n",
       "                                                                                                                             random_state=0))]))]),\n",
       "                                                  'party_affiliation')])),\n",
       "                ('classifier', MultinomialNB(alpha=0.01))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_glove.fit(data_features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05454e72",
   "metadata": {},
   "source": [
    "<span style='color:mediumpurple'><font size=\"6\">__Prediction__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3830631",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p=pipeline_glove.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab564c5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <span style='color:darkblue'><font size=\"4\"><b>CONCLUSION ALGORITHMS</b></font></span><br><br> <span style='color:black'> After several machine algorithms, we can conclude that the multinomial gives us the best accuracy (58% against ...). </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5099630b",
   "metadata": {},
   "source": [
    "<span style='color:mediumpurple'><font size=\"6\">__Submission__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4adb788",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = test_nolabel['id']\n",
    "dfsubmission = pd.DataFrame({'id': id, 'label': y_p}, columns=[\"id\", \"label\"])\n",
    "dfsubmission.to_csv('submission58MultinomialColAll.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c43ac7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <span style='color:purple'><font size=\"4\"><b>CONCLUSION GENERALE</b></font></span><br><br> <span style='color:black'> This methods, by applying complete natural language processing to each features in parallel using a pipeline gives us the best accuracy of 58.2%, using a multinomial classification algorithm. </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4f8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
