{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "542f2071",
   "metadata": {},
   "source": [
    "<span style='color:darkcyan'><font size=\"3\">__Juan Sebastian Deslarzes__</font></span><br>\n",
    "<span style='color:darkcyan'><font size=\"3\">__Chloé De Ancos__</font></span><br>\n",
    "<span style='color:darkcyan'><font size=\"3\">__Anaïs Burrus__</font></span><br>\n",
    "<span style='color:darkcyan'><font size=\"3\">__Margot Chapot__</font></span><br>\n",
    "<span style='color:darkcyan'><font size=\"3\">__Eva Sarlin__</font></span><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6518a6",
   "metadata": {},
   "source": [
    "<span style='color:darkcyan'><font size=\"8\">__Notebook 2 : Concatenation Method__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b8d5e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n",
       "  const css_urls = [];\n",
       "  \n",
       "\n",
       "  const inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from IPython import display\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "output_notebook()\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dea02d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/evasarlin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from collections import Counter \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import string\n",
    "\n",
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd8e154",
   "metadata": {},
   "source": [
    "<span style='color:mediumpurple'><font size=\"6\">__Data Loading__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34777443",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_url = 'https://raw.githubusercontent.com/esarlin/Challenge-2-CDAW/main/sitc-challenge2-2022/sample_submission.csv'\n",
    "test_nolabel_url= 'https://raw.githubusercontent.com/esarlin/Challenge-2-CDAW/main/sitc-challenge2-2022/test_nolabel.csv'\n",
    "train_url = 'https://raw.githubusercontent.com/esarlin/Challenge-2-CDAW/main/sitc-challenge2-2022/train.csv'\n",
    "\n",
    "sample_submission= pd.read_csv(sample_submission_url)\n",
    "test_nolabel = pd.read_csv(test_nolabel_url)\n",
    "train = pd.read_csv(train_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb454c33",
   "metadata": {},
   "source": [
    "<span style='color:mediumpurple'><font size=\"6\">__Data Visualization__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b84a83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>state_info</th>\n",
       "      <th>party_affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81f884c64a7</td>\n",
       "      <td>1</td>\n",
       "      <td>China is in the South China Sea and (building)...</td>\n",
       "      <td>china,foreign-policy,military</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>President-Elect</td>\n",
       "      <td>New York</td>\n",
       "      <td>republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30c2723a188</td>\n",
       "      <td>0</td>\n",
       "      <td>With the resources it takes to execute just ov...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>chris-dodd</td>\n",
       "      <td>U.S. senator</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6936b216e5d</td>\n",
       "      <td>0</td>\n",
       "      <td>The (Wisconsin) governor has proposed tax give...</td>\n",
       "      <td>corporations,pundits,taxes,abc-news-week</td>\n",
       "      <td>donna-brazile</td>\n",
       "      <td>Political commentator</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>democrat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b5cd9195738</td>\n",
       "      <td>1</td>\n",
       "      <td>Says her representation of an ex-boyfriend who...</td>\n",
       "      <td>candidates-biography,children,ethics,families,...</td>\n",
       "      <td>rebecca-bradley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84f8dac7737</td>\n",
       "      <td>0</td>\n",
       "      <td>At protests in Wisconsin against proposed coll...</td>\n",
       "      <td>health-care,labor,state-budget</td>\n",
       "      <td>republican-party-wisconsin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>republican</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  label                                          statement  \\\n",
       "0  81f884c64a7      1  China is in the South China Sea and (building)...   \n",
       "1  30c2723a188      0  With the resources it takes to execute just ov...   \n",
       "2  6936b216e5d      0  The (Wisconsin) governor has proposed tax give...   \n",
       "3  b5cd9195738      1  Says her representation of an ex-boyfriend who...   \n",
       "4  84f8dac7737      0  At protests in Wisconsin against proposed coll...   \n",
       "\n",
       "                                             subject  \\\n",
       "0                      china,foreign-policy,military   \n",
       "1                                        health-care   \n",
       "2           corporations,pundits,taxes,abc-news-week   \n",
       "3  candidates-biography,children,ethics,families,...   \n",
       "4                     health-care,labor,state-budget   \n",
       "\n",
       "                      speaker            speaker_job        state_info  \\\n",
       "0                donald-trump        President-Elect          New York   \n",
       "1                  chris-dodd           U.S. senator       Connecticut   \n",
       "2               donna-brazile  Political commentator  Washington, D.C.   \n",
       "3             rebecca-bradley                    NaN               NaN   \n",
       "4  republican-party-wisconsin                    NaN         Wisconsin   \n",
       "\n",
       "  party_affiliation  \n",
       "0        republican  \n",
       "1          democrat  \n",
       "2          democrat  \n",
       "3              none  \n",
       "4        republican  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "469de283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data train dimensions :  (8950, 8)\n",
      "Unique values for label :  [1 0]\n",
      "Number of unique values for statement:  8939\n",
      "Number of unique values for subject:  3409\n",
      "Number of unique values for speaker:  2634\n",
      "Number of unique values for speaker job:  1092\n",
      "Number of unique values for state information:  80\n",
      "Number of unique values for party affiliation:  24\n"
     ]
    }
   ],
   "source": [
    "print('Data train dimensions : ', train.shape)\n",
    "print('Unique values for label : ', train['label'].unique())\n",
    "print(\"Number of unique values for statement: \", train['statement'].unique().size)\n",
    "print(\"Number of unique values for subject: \", (train['subject'].unique()).size)\n",
    "print(\"Number of unique values for speaker: \", (train['speaker'].unique()).size)\n",
    "print(\"Number of unique values for speaker job: \", (train['speaker_job'].unique()).size)\n",
    "print(\"Number of unique values for state information: \", (train['state_info'].unique()).size)\n",
    "print(\"Number of unique values for party affiliation: \", (train['party_affiliation'].unique()).size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c310a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <span style='color:darkblue'><font size=\"4\"><b>CONCLUSION DATA VISUALIZATION</b></font></span><br><br> <span style='color:black'> As we can see we have a training set of 8950 instances, with 7 columns. We face a classification problem with the target being the column \"label\" taking as values 0 or 1. We have 6 features, each of them having a large number of possible values. This is due to the fact that these features contain strings, generating a large number of possibilities. The challenge is going to find a way to process these strings in order to use them as input of classification machine learning algorithms. In this notebook we will focus on one of the 3 methods we found, this one being called the \"concatenation\" method. </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe375e16",
   "metadata": {},
   "source": [
    "<span style='color:mediumpurple'><font size=\"6\">__Feature Selection and Cleaning__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a73e7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['speaker_job']= train['speaker_job'].fillna('u.s. senator')\n",
    "test_nolabel['speaker_job']= test_nolabel['speaker_job'].fillna('u.s. senator')\n",
    "\n",
    "train['state_info']= train['state_info'].fillna('unknown')\n",
    "test_nolabel['state_info']= test_nolabel['state_info'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd8e553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec=CountVectorizer()\n",
    "\n",
    "X1 = train['statement']\n",
    "y = train['label']\n",
    "X_test1 = test_nolabel['statement']\n",
    "\n",
    "X2 = train['subject']\n",
    "X_test2 = test_nolabel['subject']\n",
    "\n",
    "X3 = train['speaker']\n",
    "X_test3 = test_nolabel['speaker']\n",
    "\n",
    "X4 = train['speaker_job']\n",
    "X_test4 = test_nolabel['speaker_job']\n",
    "\n",
    "X5 = train['state_info']\n",
    "X_test5 = test_nolabel['state_info'] \n",
    "\n",
    "X6 = train['party_affiliation']\n",
    "X_test6 = test_nolabel['party_affiliation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de961f1d",
   "metadata": {},
   "source": [
    "<span style='color:mediumpurple'><font size=\"6\">__NLP__</font></span><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3393fab",
   "metadata": {},
   "source": [
    "<span style='color:steelblue'><font size=\"3\">__The idea is to create dataframes for train and test for each features and to concatenate them at the end with the aim to pass the total dataframe to a classifier. As the classifier will only accept numerical values we need to vectorize the content of each features.__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "135d0c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec=CountVectorizer(stop_words='english').fit(X1)\n",
    "statement_train=pd.DataFrame(cvec.transform(X1).todense(),columns=cvec.get_feature_names_out())\n",
    "statement_test=pd.DataFrame(cvec.transform(X_test1).todense(),columns=cvec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5cd5168",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec=CountVectorizer(stop_words='english').fit(X2)\n",
    "subject_train= pd.DataFrame(cvec.transform(X2).todense(),columns=cvec.get_feature_names_out())\n",
    "subject_test= pd.DataFrame(cvec.transform(X_test2).todense(),columns=cvec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72cf7df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec=CountVectorizer(stop_words='english').fit(X3)\n",
    "speaker_train= pd.DataFrame(cvec.transform(X3).todense(),columns=cvec.get_feature_names_out())\n",
    "speaker_test= pd.DataFrame(cvec.transform(X_test3).todense(),columns=cvec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1d82a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec=CountVectorizer(stop_words='english').fit(X4)\n",
    "speakerjob_train= pd.DataFrame(cvec.transform(X4).todense(),columns=cvec.get_feature_names_out())\n",
    "speakerjob_test= pd.DataFrame(cvec.transform(X_test4).todense(),columns=cvec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aaecdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec=CountVectorizer(stop_words='english').fit(X5)\n",
    "state_train= pd.DataFrame(cvec.transform(X5).todense(),columns=cvec.get_feature_names_out())\n",
    "state_test= pd.DataFrame(cvec.transform(X_test5).todense(),columns=cvec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c97eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec=CountVectorizer(stop_words='english').fit(X6)\n",
    "party_train= pd.DataFrame(cvec.transform(X6).todense(),columns=cvec.get_feature_names_out())\n",
    "party_test= pd.DataFrame(cvec.transform(X_test6).todense(),columns=cvec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca33d3f",
   "metadata": {},
   "source": [
    "<span style='color:steelblue'><font size=\"3\">__Now we have 6 different pairs of dataframe with the features content vectorized. Let's put them together :__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32372ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train=pd.concat([statement_train, subject_train, speaker_train, speakerjob_train, state_train, party_train], axis=1)\n",
    "total_test=pd.concat([statement_test, subject_test, speaker_test, speakerjob_test, state_test , party_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8c400c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8950, 15503)\n",
      "(3836, 15503)\n"
     ]
    }
   ],
   "source": [
    "print (total_train.shape)\n",
    "print (total_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a48f5",
   "metadata": {},
   "source": [
    "<span style='color:steelblue'><font size=\"3\">__Now that we have one big dataframe with numerical values we can pass it to a classifier:__</font></span><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb004b0",
   "metadata": {},
   "source": [
    "<span style='color:mediumpurple'><font size=\"6\">__Machine Learning Classification__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "396244da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6af2fdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evasarlin/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(total_train,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f218d",
   "metadata": {},
   "source": [
    "<span style='color:mediumpurple'><font size=\"6\">__Ensemble__</font></span><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e821bd9",
   "metadata": {},
   "source": [
    "\n",
    "<span style='color:steelblue'><font size=\"3\">__Testing the accuracy of different machine learning algorithms on a subset of the train :__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcd642ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(total_train, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0526cf",
   "metadata": {},
   "source": [
    "<span style='color:green'><font size=\"3\">__Random Forest:__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fa8b17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000, random_state=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier1 = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier1.fit(X_train, y_train) \n",
    "print(classification_report(y_test, classifier1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8ecc8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.13      0.21       623\n",
      "           1       0.67      0.95      0.79      1167\n",
      "\n",
      "    accuracy                           0.67      1790\n",
      "   macro avg       0.63      0.54      0.50      1790\n",
      "weighted avg       0.64      0.67      0.59      1790\n",
      "\n",
      "0.6653631284916202\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64d739f7",
   "metadata": {},
   "source": [
    "<span style='color:green'><font size=\"3\">__Naives Bayes:__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d29b92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.63      0.47       623\n",
      "           1       0.69      0.45      0.55      1167\n",
      "\n",
      "    accuracy                           0.51      1790\n",
      "   macro avg       0.54      0.54      0.51      1790\n",
      "weighted avg       0.58      0.51      0.52      1790\n",
      "\n",
      "0.5128491620111731\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier2 = GaussianNB()\n",
    "classifier2.fit(X_train, y_train)\n",
    "print(classification_report(y_test, classifier2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624696ae",
   "metadata": {},
   "source": [
    "<span style='color:green'><font size=\"3\">__K Nearest Neighbors__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02aae742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.29      0.36       623\n",
      "           1       0.68      0.82      0.75      1167\n",
      "\n",
      "    accuracy                           0.63      1790\n",
      "   macro avg       0.57      0.55      0.55      1790\n",
      "weighted avg       0.61      0.63      0.61      1790\n",
      "\n",
      "0.6346368715083799\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier3 = KNeighborsClassifier(n_neighbors=10)\n",
    "classifier3.fit(X_train, y_train)\n",
    "print(classification_report(y_test, classifier3.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53473cf",
   "metadata": {},
   "source": [
    "<span style='color:green'><font size=\"3\">__Decision Tree:__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fa6dd0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.40      0.42       623\n",
      "           1       0.69      0.73      0.71      1167\n",
      "\n",
      "    accuracy                           0.61      1790\n",
      "   macro avg       0.57      0.56      0.56      1790\n",
      "weighted avg       0.61      0.61      0.61      1790\n",
      "\n",
      "0.6134078212290502\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "classifier4 = tree.DecisionTreeClassifier()\n",
    "classifier4.fit(X_train, y_train)\n",
    "print(classification_report(y_test, classifier4.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd8c34",
   "metadata": {},
   "source": [
    "<span style='color:green'><font size=\"3\">__Multi Layers Perceptron:__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "594f0c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.43      0.43       623\n",
      "           1       0.70      0.71      0.70      1167\n",
      "\n",
      "    accuracy                           0.61      1790\n",
      "   macro avg       0.57      0.57      0.57      1790\n",
      "weighted avg       0.61      0.61      0.61      1790\n",
      "\n",
      "0.6094972067039106\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "classifier5 = MLPClassifier(random_state=1, max_iter=300)\n",
    "classifier5.fit(X_train, y_train)\n",
    "print(classification_report(y_test, classifier5.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb07a5d",
   "metadata": {},
   "source": [
    "<span style='color:green'><font size=\"3\">__Support Vector Classifier SVC:__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccdac4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evasarlin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/evasarlin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/evasarlin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       623\n",
      "           1       0.65      1.00      0.79      1167\n",
      "\n",
      "    accuracy                           0.65      1790\n",
      "   macro avg       0.33      0.50      0.39      1790\n",
      "weighted avg       0.43      0.65      0.51      1790\n",
      "\n",
      "0.6519553072625698\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier6 = SVC(gamma='auto')\n",
    "classifier6.fit(X_train, y_train)\n",
    "print(classification_report(y_test, classifier6.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8af1c4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <span style='color:darkblue'><font size=\"4\"><b>CONCLUSION ALGORITHMS</b></font></span><br><br> <span style='color:black'> After testing several algorithms and submit their predictions on kaggle, we found that the regression was the best classifier, giving us an accuracy above 57% whereas Random Frest and SVC were not performing well (51% and 50,5%), even if they showed accuracy of 65% on teh training subset. </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a239da5c",
   "metadata": {},
   "source": [
    "\n",
    "<span style='color:steelblue'><font size=\"5\">__Tuning of hyperparameters using genetic algorithms :__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b3a459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_kNN = [{'n_neighbors': [10, 12, 15], # np.arange(4, 10),\n",
    "                    # 'weights': ['uniform', 'distance'],\n",
    "                    'algorithm':['auto', 'ball_tree'] #, 'kd_tree', 'brute']\n",
    "                            \n",
    "                    }]\n",
    "\n",
    "param_grid_mlp = [{'activation': ['logistic','tanh','relu'],\n",
    "                    'solver':['lbfgs', 'sgd', 'adam']         \n",
    "                    }]\n",
    "\n",
    "param_grid_mb = [{'alpha': np.arange(0.1, 0.5),    \n",
    "                    }]\n",
    "\n",
    "param_grid_DT = [{'criterion': ['gini', 'entropy'], \n",
    "                  'max_leaf_nodes' : np.arange(2,30),\n",
    "                  'max_depth' : np.arange(2,6)\n",
    "                    }]\n",
    "\n",
    "param_grid_RF =  [{ #'bootstrap': [True, False],\n",
    "                     'max_depth': [15, None],\n",
    "                    # 'max_features': ['auto', 'sqrt'],\n",
    "                   #  'min_samples_leaf': [1, 2, 4],\n",
    "                    # 'min_samples_split': [2, 5, 10],\n",
    "                     'n_estimators': [200, 400]\n",
    "                  }]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94144f3c",
   "metadata": {},
   "source": [
    "\n",
    "<span style='color:red'><font size=\"5\">__Disclaimer : takes too much time for you to run__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1de95453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evasarlin/opt/anaconda3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/Users/evasarlin/opt/anaconda3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types [1, 1] and maxint [0, 1] detected\n",
      "--- Evolve in 2 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd       \n",
      "0  \t50    \t0.643235\t0.642179\t0.644693\t0.00124079\n",
      "1  \t34    \t0.644693\t0.644693\t0.644693\t1.11022e-16\n",
      "2  \t30    \t0.644693\t0.644693\t0.644693\t1.11022e-16\n",
      "3  \t35    \t0.644592\t0.642179\t0.644693\t0.000492635\n",
      "4  \t30    \t0.644592\t0.642179\t0.644693\t0.000492635\n",
      "5  \t27    \t0.644642\t0.642179\t0.644693\t0.000351955\n",
      "6  \t27    \t0.644693\t0.644693\t0.644693\t1.11022e-16\n",
      "7  \t25    \t0.644693\t0.644693\t0.644693\t1.11022e-16\n",
      "8  \t23    \t0.644693\t0.644693\t0.644693\t1.11022e-16\n",
      "9  \t26    \t0.644693\t0.644693\t0.644693\t1.11022e-16\n",
      "10 \t28    \t0.644642\t0.642179\t0.644693\t0.000351955\n",
      "Best individual is: {'n_neighbors': 15, 'algorithm': 'ball_tree'}\n",
      "with fitness: 0.6446927374301676\n",
      "CPU times: user 8min 55s, sys: 8.24 s, total: 9min 3s\n",
      "Wall time: 9min 6s\n"
     ]
    }
   ],
   "source": [
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kNN_GA = EvolutionaryAlgorithmSearchCV(estimator=KNeighborsClassifier(),\n",
    "                                       params=param_grid_kNN,\n",
    "                                       scoring=\"accuracy\",\n",
    "                                       cv=StratifiedKFold(n_splits=2),\n",
    "                                       verbose=True,\n",
    "                                       population_size=50,\n",
    "                                       gene_mutation_prob=0.10,\n",
    "                                       tournament_size=20,\n",
    "                                       generations_number=10)\n",
    "%time kNN_GA.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85fe002a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evasarlin/opt/anaconda3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/Users/evasarlin/opt/anaconda3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types [1, 1] and maxint [3, 2] detected\n",
      "--- Evolve in 12 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd       \n",
      "0  \t50    \t0.650115\t0.646369\t0.653631\t0.00303939\n",
      "1  \t38    \t0.653575\t0.652095\t0.653631\t0.000263519\n",
      "2  \t26    \t0.653525\t0.648324\t0.653631\t0.000743017\n",
      "3  \t19    \t0.653564\t0.652095\t0.653631\t0.000301158\n",
      "4  \t34    \t0.653542\t0.652095\t0.653631\t0.000334916\n",
      "5  \t27    \t0.653628\t0.653492\t0.653631\t1.95531e-05\n",
      "6  \t34    \t0.653316\t0.646369\t0.653631\t0.00109254 \n",
      "7  \t30    \t0.653567\t0.652095\t0.653631\t0.000301119\n",
      "8  \t35    \t0.653564\t0.652095\t0.653631\t0.000301158\n",
      "9  \t27    \t0.653606\t0.652514\t0.653631\t0.000157245\n",
      "10 \t22    \t0.653598\t0.652095\t0.653631\t0.000215573\n",
      "Best individual is: {'max_depth': None, 'n_estimators': 200}\n",
      "with fitness: 0.6536312849162011\n",
      "CPU times: user 32min 47s, sys: 45.4 s, total: 33min 32s\n",
      "Wall time: 36min 19s\n"
     ]
    }
   ],
   "source": [
    "RF_GA = EvolutionaryAlgorithmSearchCV(estimator=RandomForestClassifier(),\n",
    "                                       params=param_grid_RF,\n",
    "                                       scoring=\"accuracy\",\n",
    "                                       cv=StratifiedKFold(n_splits=2),\n",
    "                                       verbose=True,\n",
    "                                       population_size=50,\n",
    "                                       gene_mutation_prob=0.10,\n",
    "                                       tournament_size=20,\n",
    "                                       generations_number=10)\n",
    "%time RF_GA.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55132ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_GA = EvolutionaryAlgorithmSearchCV(estimator=MLPClassifier(),\n",
    "                                       params=param_grid_mlp,\n",
    "                                       scoring=\"accuracy\",\n",
    "                                       cv=StratifiedKFold(n_splits=2),\n",
    "                                       verbose=True,\n",
    "                                       population_size=50,\n",
    "                                       gene_mutation_prob=0.10,\n",
    "                                       tournament_size=20,\n",
    "                                       generations_number=10)\n",
    "%time MLP_GA.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6f2b8d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evasarlin/opt/anaconda3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/Users/evasarlin/opt/anaconda3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types [2] and maxint [0] detected\n",
      "--- Evolve in 1 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd        \n",
      "0  \t50    \t0.597207\t0.597207\t0.597207\t1.11022e-16\n",
      "1  \t26    \t0.597207\t0.597207\t0.597207\t1.11022e-16\n",
      "2  \t29    \t0.597207\t0.597207\t0.597207\t1.11022e-16\n",
      "3  \t28    \t0.597207\t0.597207\t0.597207\t1.11022e-16\n",
      "4  \t25    \t0.597207\t0.597207\t0.597207\t1.11022e-16\n",
      "5  \t39    \t0.597207\t0.597207\t0.597207\t1.11022e-16\n",
      "6  \t30    \t0.597207\t0.597207\t0.597207\t1.11022e-16\n",
      "7  \t35    \t0.597207\t0.597207\t0.597207\t1.11022e-16\n",
      "8  \t31    \t0.597207\t0.597207\t0.597207\t1.11022e-16\n",
      "9  \t33    \t0.597207\t0.597207\t0.597207\t1.11022e-16\n",
      "10 \t35    \t0.597207\t0.597207\t0.597207\t1.11022e-16\n",
      "Best individual is: {'alpha': 0.1}\n",
      "with fitness: 0.5972067039106145\n",
      "CPU times: user 3.96 s, sys: 1.3 s, total: 5.26 s\n",
      "Wall time: 4.9 s\n"
     ]
    }
   ],
   "source": [
    "MB_GA = EvolutionaryAlgorithmSearchCV(estimator=MultinomialNB(),\n",
    "                                       params=param_grid_mb,\n",
    "                                       scoring=\"accuracy\",\n",
    "                                       cv=StratifiedKFold(n_splits=2),\n",
    "                                       verbose=True,\n",
    "                                       population_size=50,\n",
    "                                       gene_mutation_prob=0.10,\n",
    "                                       tournament_size=20,\n",
    "                                       generations_number=10)\n",
    "%time MB_GA.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87200326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evasarlin/opt/anaconda3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/Users/evasarlin/opt/anaconda3/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types [1, 1, 1] and maxint [1, 27, 3] detected\n",
      "--- Evolve in 224 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd        \n",
      "0  \t50    \t0.646115\t0.645391\t0.646927\t0.000412132\n",
      "1  \t28    \t0.646698\t0.64581 \t0.646927\t0.000273344\n",
      "2  \t26    \t0.646927\t0.646927\t0.646927\t1.11022e-16\n",
      "3  \t30    \t0.646877\t0.645531\t0.646927\t0.000221288\n",
      "4  \t29    \t0.646891\t0.64595 \t0.646927\t0.00016    \n",
      "5  \t33    \t0.646891\t0.646369\t0.646927\t0.000127425\n",
      "6  \t30    \t0.646902\t0.64595 \t0.646927\t0.000141579\n",
      "7  \t22    \t0.646922\t0.646648\t0.646927\t3.91061e-05\n",
      "8  \t30    \t0.646927\t0.646927\t0.646927\t1.11022e-16\n",
      "9  \t30    \t0.646927\t0.646927\t0.646927\t1.11022e-16\n",
      "10 \t26    \t0.646894\t0.645531\t0.646927\t0.000198619\n",
      "Best individual is: {'criterion': 'gini', 'max_leaf_nodes': 20, 'max_depth': 5}\n",
      "with fitness: 0.646927374301676\n",
      "CPU times: user 3min 7s, sys: 1min 4s, total: 4min 12s\n",
      "Wall time: 4min 13s\n"
     ]
    }
   ],
   "source": [
    "DT_GA = EvolutionaryAlgorithmSearchCV(estimator=tree.DecisionTreeClassifier(),\n",
    "                                       params=param_grid_DT,\n",
    "                                       scoring=\"accuracy\",\n",
    "                                       cv=StratifiedKFold(n_splits=2),\n",
    "                                       verbose=True,\n",
    "                                       population_size=50,\n",
    "                                       gene_mutation_prob=0.10,\n",
    "                                       tournament_size=20,\n",
    "                                       generations_number=10)\n",
    "%time DT_GA.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e338b4",
   "metadata": {},
   "source": [
    "<span style='color:steelblue'><font size=\"5\">__Let's combine some of these algoritms in a Voting classifier :__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "VotingModel = VotingClassifier(estimators=[('knn', KNeighborsClassifier(n_neighbors=15)), ('mlp', MLPClassifier(random_state=1, max_iter=300)), ('lr', lr),  ('svc',SVC(gamma='auto')), ('RF', RandomForestClassifier(n_estimators=1000, random_state=0)), ('tree', tree.DecisionTreeClassifier(criterion='gini', max_depth=5,  max_leaf_nodes=20))], voting='hard')\n",
    "VotingModel.fit(total_train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4576fd3",
   "metadata": {},
   "source": [
    "<span style='color:mediumpurple'><font size=\"6\">__Prediction__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d126f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=lr.predict(total_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "06eb54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=VotingModel.predict(total_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5099630b",
   "metadata": {},
   "source": [
    "<span style='color:mediumpurple'><font size=\"6\">__Submission__</font></span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e4adb788",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = test_nolabel['id']\n",
    "dfsubmission = pd.DataFrame({'id': id, 'label': ypred}, columns=[\"id\", \"label\"])\n",
    "dfsubmission.to_csv('concatenationVoting2.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c43ac7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <span style='color:purple'><font size=\"4\"><b>CONCLUSION GENERALE</b></font></span><br><br> <span style='color:black'> To sum up, we tried another way to combine the different features. This time the content of each feature was vectorized to obtain a dataframe of numerical values, and the resulting dataframes were concatenated and passed to machine learning classifiers. As machine learning algorithms, we tested several algorithms and concluded that the regression fits the best this implementation. We also used genetic algorithms to tune the hyperparameters using a subset of the provided training set. Finally we used all these algorithms in a Voting Classifier. </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4f8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
